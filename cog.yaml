build:
  gpu: true
  cuda: "12.1"  # Use 12.1 instead of 12.2 for better compatibility
  python_version: "3.11"
  python_requirements: "requirements.txt"
  
  system_packages:
    - libgl1-mesa-glx
    - libglib2.0-0
    - libgomp1
    - wget
    - build-essential
    - ninja-build  # Required for Flash Attention
    - git
    - git-lfs
    - ffmpeg

  run:
    # Download pget for faster downloads
    - curl -o /usr/local/bin/pget -L "https://github.com/replicate/pget/releases/latest/download/pget_$(uname -s)_$(uname -m)" && chmod +x /usr/local/bin/pget
    # Set up CUDA environment
    - echo "Setting up CUDA environment..." && export CUDA_HOME=/usr/local/cuda && export PATH=${CUDA_HOME}/bin:${PATH} && export LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}
    # Install PyTorch with CUDA 12.1 support
    - pip install --extra-index-url https://download.pytorch.org/whl/cu121 torch torchvision
    # Install build dependencies
    - echo "Installing build dependencies..." && pip install --upgrade pip setuptools wheel
    # Install PyTorch Geometric dependencies for CUDA 12.1
    - echo "Installing PyTorch Geometric dependencies..." && pip install torch_scatter torch_cluster -f https://data.pyg.org/whl/torch-2.4.0+cu121.html --no-cache-dir || pip install torch_scatter torch_cluster -f https://data.pyg.org/whl/torch-2.3.0+cu121.html --no-cache-dir
    # Install spconv for CUDA 12.1
    - echo "Installing spconv..." && pip install spconv-cu121
    # Install Flash Attention with proper dependencies
    - echo "Installing Flash Attention..." && pip install packaging ninja
    - pip install flash-attn==2.8.1 --no-build-isolation
    # Set environment variables for consistent behavior
    - export TORCH_CUDA_ARCH_LIST="8.0;8.6;8.9;9.0" && export OMP_NUM_THREADS=1

predict: "predict.py:Predictor" 